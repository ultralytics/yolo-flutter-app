// Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

package com.ultralytics.yolo

import android.content.Context
import android.graphics.*
import android.util.Log
import android.util.Size
import org.tensorflow.lite.DataType
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.gpu.GpuDelegate
import org.tensorflow.lite.support.common.FileUtil
import org.tensorflow.lite.support.common.ops.CastOp
import org.tensorflow.lite.support.common.ops.NormalizeOp
import org.tensorflow.lite.support.image.ImageProcessor
import org.tensorflow.lite.support.image.TensorImage
import org.tensorflow.lite.support.image.ops.ResizeOp
import org.tensorflow.lite.support.image.ops.Rot90Op
import org.tensorflow.lite.support.metadata.MetadataExtractor
import org.tensorflow.lite.support.metadata.schema.ModelMetadata
import org.yaml.snakeyaml.Yaml
import java.nio.ByteBuffer
import java.nio.ByteOrder
import kotlin.math.max
import kotlin.math.min
import androidx.collection.ArrayMap

class PoseEstimator(
    context: Context,
    modelPath: String,
    override var labels: List<String>,
    private val useGpu: Boolean = true,
    private val confidenceThreshold: Float = 0.25f,   // ä»»æ„ã§å¤‰æ›´
    private val iouThreshold: Float = 0.45f,          // ä»»æ„ã§å¤‰æ›´
    private val customOptions: Interpreter.Options? = null
) : BasePredictor() {

    companion object {
        private const val TAG = "ğŸƒ PoseEstimator"
        // xywh(4) + conf(1) + keypoints(17*3=51) = 56
        private const val OUTPUT_FEATURES = 56
        private const val KEYPOINTS_COUNT = 17
        private const val KEYPOINTS_FEATURES = KEYPOINTS_COUNT * 3 // x, y, conf per keypoint
        private const val MAX_POOL_SIZE = 100  // æœ€å¤§ãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚º
        
        // æ¨™æº–çš„ãªå…¥åŠ›ã‚µã‚¤ã‚º (é€šå¸¸ã¯ 640)
        private const val INPUT_SIZE = 640
    }
    
    // Box ãŠã‚ˆã³ Keypoints ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ¼ãƒ«
    private val boxPool = ObjectPool<Box>(MAX_POOL_SIZE) { Box(0, "", 0f, RectF(), RectF()) }
    private val keypointsPool = ObjectPool<Keypoints>(MAX_POOL_SIZE) {
        Keypoints(
            List(KEYPOINTS_COUNT) { 0f to 0f },
            List(KEYPOINTS_COUNT) { 0f to 0f },
            List(KEYPOINTS_COUNT) { 0f }
        )
    }
    
    // ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç®¡ç†ã‚¯ãƒ©ã‚¹
    private class ObjectPool<T>(
        private val maxSize: Int,
        private val factory: () -> T
    ) {
        private val pool = ArrayList<T>(maxSize)
        
        @Synchronized
        fun acquire(): T {
            return if (pool.isEmpty()) {
                factory()
            } else {
                pool.removeAt(pool.size - 1)
            }
        }
        
        @Synchronized
        fun release(obj: T) {
            if (pool.size < maxSize) {
                pool.add(obj)
            }
        }
        
        @Synchronized
        fun clear() {
            pool.clear()
        }
    }

    private val interpreterOptions = (customOptions ?: Interpreter.Options()).apply {
        // If no custom options provided, use default threads
        if (customOptions == null) {
            setNumThreads(Runtime.getRuntime().availableProcessors())
        }
        
        if (useGpu) {
            try {
                addDelegate(GpuDelegate())
                Log.d("PoseEstimator", "GPU delegate is used.")
            } catch (e: Exception) {
                Log.e("PoseEstimator", "GPU delegate error: ${e.message}")
            }
        }
    }

    private lateinit var imageProcessorCamera: ImageProcessor
    private lateinit var imageProcessorSingleImage: ImageProcessor
    
    // Reuse ByteBuffer for input to reduce allocations
    private lateinit var inputBuffer: ByteBuffer
    
    // Reuse output arrays to reduce allocations
    private lateinit var outputArray: Array<Array<FloatArray>>
    
    // Output dimensions
    private var batchSize = 0
    private var numAnchors = 0

    init {
        // (1) TFLiteãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ (æ‹¡å¼µå­è‡ªå‹•ä»˜ä¸)
        val modelBuffer = YoloUtils.loadModelFile(context, modelPath)

        // ===== ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰ =====
        try {
            val metadataExtractor = MetadataExtractor(modelBuffer)
            val modelMetadata: ModelMetadata? = metadataExtractor.modelMetadata
            if (modelMetadata != null) {
                Log.d("PoseEstimator", "Model metadata retrieved successfully.")
            }
            val associatedFiles = metadataExtractor.associatedFileNames
            if (!associatedFiles.isNullOrEmpty()) {
                for (fileName in associatedFiles) {
                    Log.d("PoseEstimator", "Found associated file: $fileName")
                    metadataExtractor.getAssociatedFile(fileName)?.use { stream ->
                        val fileContent = stream.readBytes()
                        val fileString = fileContent.toString(Charsets.UTF_8)
                        try {
                            val yaml = Yaml()
                            @Suppress("UNCHECKED_CAST")
                            val data = yaml.load<Map<String, Any>>(fileString)
                            if (data != null && data.containsKey("names")) {
                                val namesMap = data["names"] as? Map<Int, String>
                                if (namesMap != null) {
                                    this.labels = namesMap.values.toList()
                                    Log.d("PoseEstimator", "Loaded labels from metadata: $labels")
                                } else {

                                }
                            } else {

                            }
                        } catch (ex: Exception) {
                            Log.e("PoseEstimator", "Failed to parse YAML from metadata: ${ex.message}")
                        }
                    }
                }
            } else {
                Log.d("PoseEstimator", "No associated files found in the metadata.")
            }
        } catch (e: Exception) {
            Log.e("PoseEstimator", "Failed to extract metadata: ${e.message}")
        }

        // (2) Interpreterã®ç”Ÿæˆ
        interpreter = Interpreter(modelBuffer, interpreterOptions)
        // Call allocateTensors() once during initialization
        interpreter.allocateTensors()
        Log.d("PoseEstimator", "TFLite model loaded and tensors allocated")

        // (3) å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶ã‚’å–å¾—: [1, height, width, 3]
        val inputShape = interpreter.getInputTensor(0).shape()
        val inHeight = inputShape[1]
        val inWidth = inputShape[2]
        inputSize = com.ultralytics.yolo.Size(inWidth, inHeight)
        modelInputSize = Pair(inWidth, inHeight)
        
        // å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶ã‚’å–å¾—ãƒ»åˆæœŸåŒ–
        val outputShape = interpreter.getOutputTensor(0).shape()  // ä¾‹: [1, 56, 2100]
        batchSize = outputShape[0]           // 1
        val outFeatures = outputShape[1]     // 56
        numAnchors = outputShape[2]          // 2100ç­‰
        require(outFeatures == OUTPUT_FEATURES) {
            "Unexpected output feature size. Expected=$OUTPUT_FEATURES, Actual=$outFeatures"
        }
        
        // å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–
        outputArray = Array(batchSize) {
            Array(outFeatures) { FloatArray(numAnchors) }
        }
        
        // å…¥åŠ›ãƒãƒƒãƒ•ã‚¡ã®åˆæœŸåŒ– (ç›´æ¥ç¢ºä¿ + ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚ªãƒ¼ãƒ€ãƒªãƒ³ã‚°)
        val inputBytes = 1 * inHeight * inWidth * 3 * 4 // FLOAT32ã¯4ãƒã‚¤ãƒˆ
        inputBuffer = ByteBuffer.allocateDirect(inputBytes).apply {
            order(java.nio.ByteOrder.nativeOrder())
        }
        Log.d("PoseEstimator", "Direct ByteBuffer allocated with native ordering: $inputBytes bytes")

        // (4) ImageProcessorã®åˆæœŸåŒ– - both with and without rotation
        
        // For camera feed (with rotation)
        imageProcessorCamera = ImageProcessor.Builder()
            .add(Rot90Op(3)) // å¿…è¦ã«å¿œã˜ã¦å›è»¢ã™ã‚‹å ´åˆã¯æ•°å€¤ã‚’å¤‰ãˆã¦ãã ã•ã„
            .add(ResizeOp(inHeight, inWidth, ResizeOp.ResizeMethod.BILINEAR))
            .add(NormalizeOp(0f, 255f))
            .add(CastOp(DataType.FLOAT32))
            .build()
            
        // For single images (no rotation needed)
        imageProcessorSingleImage = ImageProcessor.Builder()
            .add(ResizeOp(inHeight, inWidth, ResizeOp.ResizeMethod.BILINEAR))
            .add(NormalizeOp(0f, 255f))
            .add(CastOp(DataType.FLOAT32))
            .build()
    }

    override fun predict(bitmap: Bitmap, origWidth: Int, origHeight: Int, rotateForCamera: Boolean): YOLOResult {
        t0 = System.nanoTime()
        // (1) å‰å‡¦ç†: TensorImageã¸ãƒ­ãƒ¼ãƒ‰ & ImageProcessorã§å‡¦ç†
        val tensorImage = TensorImage(DataType.FLOAT32)
        tensorImage.load(bitmap)
        
        // Choose the appropriate processor based on input source
        val processedImage = if (rotateForCamera) {
            // Apply rotation for camera feed
            imageProcessorCamera.process(tensorImage)
        } else {
            // No rotation for single image
            imageProcessorSingleImage.process(tensorImage)
        }
        
        // å†åˆ©ç”¨å¯èƒ½ãªãƒãƒƒãƒ•ã‚¡ã¸å…¥åŠ›ã‚’ã‚³ãƒ”ãƒ¼
        inputBuffer.clear()
        inputBuffer.put(processedImage.buffer)
        inputBuffer.rewind()

        // (3) æ¨è«–å®Ÿè¡Œ (å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã¯åˆæœŸåŒ–æ™‚ã«ç¢ºä¿æ¸ˆã¿)
        interpreter.run(inputBuffer, outputArray)
        // å‡¦ç†æ™‚é–“ã®è¨ˆæ¸¬æ›´æ–°
        updateTiming()

        // (4) å¾Œå‡¦ç†: NMS + ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆè¨ˆç®—
        val rawDetections = postProcessPose(
            features = outputArray[0],  // shape: [56][numAnchors]
            numAnchors = numAnchors,
            confidenceThreshold = confidenceThreshold,
            iouThreshold = iouThreshold,
            origWidth = origWidth,
            origHeight = origHeight
        )

        // æ¤œå‡ºçµæœã‚’å–ã‚Šå‡ºã—
        val boxes = rawDetections.map { it.box }
        val keypointsList = rawDetections.map { it.keypoints }

        // ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ“ãƒƒãƒˆãƒãƒƒãƒ—ç”Ÿæˆ
//        val annotatedImage = drawPoseOnBitmap(bitmap, keypointsList, boxes)

        val fpsDouble: Double = if (t4 > 0) (1.0 / t4) else 0.0
        
        Log.d(TAG, "ğŸ“¦ Creating YOLOResult - boxes: ${boxes.size}, keypointsList: ${keypointsList.size}")
        keypointsList.forEachIndexed { idx, kps ->
            Log.d(TAG, "ğŸ“ YOLOResult keypointsList[$idx] - points: ${kps.xy.size}")
        }
        
        // YOLOResultã«è©°ã‚ã¦è¿”ã™
        return YOLOResult(
            origShape = com.ultralytics.yolo.Size(bitmap.height, bitmap.width),
            boxes = boxes,
            keypointsList = keypointsList,
//            annotatedImage = annotatedImage,
            speed = t2,   // ãƒŸãƒªç§’ç­‰ã®æ¸¬å®šå€¤ã¯BasePredictorå´ã®å®Ÿè£…æ¬¡ç¬¬
            fps = fpsDouble,
            names = labels
        )
    }

    /**
     * å¾Œå‡¦ç†: Confidenceé–¾å€¤ã§é™¤å¤–ã€NMSã§æŠ‘åˆ¶ã€åº§æ¨™å¤‰æ›ã€Keypointså‡¦ç†
     */
    private fun postProcessPose(
        features: Array<FloatArray>,
        numAnchors: Int,
        confidenceThreshold: Float,
        iouThreshold: Float,
        origWidth: Int,
        origHeight: Int
    ): List<PoseDetection> {

        val detections = mutableListOf<PoseDetection>()

        // ä¾‹ãˆã° modelInputSize = (640, 640) ã¨ä»®å®š
        val (modelW, modelH) = modelInputSize
        val scaleX = origWidth.toFloat() / modelW
        val scaleY = origHeight.toFloat() / modelH
        
        Log.d(TAG, "ğŸš€ Starting postProcessPose - numAnchors=$numAnchors")
        Log.d(TAG, "ğŸ“ Model dimensions - modelW=$modelW, modelH=$modelH")
        Log.d(TAG, "ğŸ–¼ï¸ Original image dimensions - origWidth=$origWidth, origHeight=$origHeight")
        Log.d(TAG, "ğŸ” Scale factors - scaleX=$scaleX, scaleY=$scaleY")

        for (j in 0 until numAnchors) {
            // ä¾‹: features[0][j] ~ features[3][j] ã¯ 0ï½1 ã®æ­£è¦åŒ–å€¤
            val rawX = features[0][j]       // 0..1
            val rawY = features[1][j]       // 0..1
            val rawW = features[2][j]       // 0..1
            val rawH = features[3][j]       // 0..1
            val conf = features[4][j]       // 0..1

            if (conf < confidenceThreshold) continue
            
            Log.d(TAG, "ğŸ‘¤ Detection $j - conf=$conf (threshold=$confidenceThreshold)")

            // (A) ã¾ãšæ­£è¦åŒ–ã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›è§£åƒåº¦ã«æ‹¡å¤§ (640ç­‰) ã™ã‚‹
            val xScaled = rawX * modelW
            val yScaled = rawY * modelH
            val wScaled = rawW * modelW
            val hScaled = rawH * modelH

            // [x-w/2, y-h/2, x+w/2, y+h/2] ã¯ modelInputSize ã‚¹ã‚±ãƒ¼ãƒ«
            val left   = xScaled - wScaled / 2f
            val top    = yScaled - hScaled / 2f
            val right  = xScaled + wScaled / 2f
            val bottom = yScaled + hScaled / 2f

            // modelInputSize ã‚¹ã‚±ãƒ¼ãƒ«ã§ã® RectF
            val normBox = RectF(left / modelW, top / modelH, right / modelW, bottom / modelH)

            // (B) ä»Šåº¦ã¯å®Ÿéš›ã®å…ƒç”»åƒã‚¹ã‚±ãƒ¼ãƒ«ã¸æ‹¡å¤§
            val rectF = RectF(
                left   * scaleX,
                top    * scaleY,
                right  * scaleX,
                bottom * scaleY
            )

            // ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ (5..55) ã‚‚åŒæ§˜ã«ãƒ¢ãƒ‡ãƒ«è§£åƒåº¦ â†’ å®Ÿç”»åƒã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
            val kpArray = mutableListOf<Pair<Float, Float>>()
            val kpConfArray = mutableListOf<Float>()
            Log.d(TAG, "ğŸ¦´ Detection $j - Processing $KEYPOINTS_COUNT keypoints")
            for (k in 0 until KEYPOINTS_COUNT) {
                val rawKx = features[5 + k * 3][j]
                val rawKy = features[5 + k * 3 + 1][j]
                val kpC   = features[5 + k * 3 + 2][j]

                // Check if values are already in pixel coordinates (>1) or normalized (0-1)
                val isNormalized = rawKx <= 1.0f && rawKy <= 1.0f
                
                val finalKx: Float
                val finalKy: Float
                
                if (isNormalized) {
                    // æ­£è¦åŒ–ã•ã‚ŒãŸåº§æ¨™ã®å ´åˆï¼ˆ0-1ï¼‰
                    val kxScaled = rawKx * modelW
                    val kyScaled = rawKy * modelH
                    finalKx = kxScaled * scaleX
                    finalKy = kyScaled * scaleY
                } else {
                    // ã™ã§ã«ãƒ¢ãƒ‡ãƒ«å…¥åŠ›è§£åƒåº¦ã®ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã®å ´åˆ
                    finalKx = rawKx * scaleX
                    finalKy = rawKy * scaleY
                }

                kpArray.add(finalKx to finalKy)
                kpConfArray.add(kpC)
                
                // Debug log for first 5 keypoints
                if (k < 5) {
                    Log.d(TAG, "ğŸ”µ Det[$j] KP[$k] - raw(${rawKx},${rawKy}) isNorm=$isNormalized final(${finalKx},${finalKy}) conf=$kpC")
                }
            }

            // ãƒ—ãƒ¼ãƒ«ã‹ã‚‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—ã—ã¦å†åˆ©ç”¨
            val boxObj = boxPool.acquire()
            val keypointsObj = keypointsPool.acquire()
            
            // xynãƒªã‚¹ãƒˆã‚’æº–å‚™
            val xynList = kpArray.map { (fx, fy) ->
                (fx / origWidth) to (fy / origHeight)
            }
            
            // ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ¼ãƒªãƒ³ã‚°ã®æ­£ã—ã„ä½¿ç”¨æ–¹æ³•ï¼š
            // æ–°ã—ãä½œæˆã™ã‚‹ä»£ã‚ã‚Šã«ãƒ—ãƒ¼ãƒ«ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ›´æ–°ã—ã¦å†åˆ©ç”¨ã™ã‚‹

            // Boxã‚’æ›´æ–°
            boxObj.index = 0
            boxObj.cls = "person"
            boxObj.conf = conf
            boxObj.xywh.set(rectF)
            boxObj.xywhn.set(normBox)
            
            // ä»¥ä¸‹ã®ã‚ˆã†ã«Keypointsã‚’æ›´æ–°ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½œæˆã—ã€æ—¢å­˜ã®Keypointsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ›´æ–°ã™ã‚‹
            // ã“ã“ã§ã¯ç°¡å˜ã®ãŸã‚ã«æ–°ã—ã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨
            val keypoints = Keypoints(
                xyn = xynList,
                xy = kpArray,
                conf = kpConfArray
            )
            
            Log.d(TAG, "âœ… Detection $j - Created keypoints with ${kpArray.size} points")
            val highConfKps = kpConfArray.count { it > 0.25f }
            Log.d(TAG, "ğŸ’ª Detection $j - Keypoints with conf>0.25: $highConfKps")
            
            detections.add(
                PoseDetection(
                    box = boxObj,
                    keypoints = keypoints
                )
            )
            
            // keypointsObjã¯ä½¿ç”¨ã—ãªã‹ã£ãŸã®ã§ãƒªãƒªãƒ¼ã‚¹
            keypointsPool.release(keypointsObj)
        }

        // ä»¥é™ã¯ NMS å‡¦ç† (å˜ä¸€ã‚¯ãƒ©ã‚¹æƒ³å®š) ã¯å¤‰ã‚ã‚‰ãš
        val finalDetections = nmsPoseDetections(detections, iouThreshold)
        return finalDetections
    }


    /**
     * NMSã‚’å˜ä¸€ã‚¯ãƒ©ã‚¹æƒ³å®šã§å®Ÿè¡Œ (æ‹¡å¼µã—ãŸã„å ´åˆã¯ã‚¯ãƒ©ã‚¹åˆ¥ã«åˆ†å‰²ã—ã¦NMS)
     * æœ€é©åŒ–: ã‚¹ã‚³ã‚¢ãŒä½ã„ãƒœãƒƒã‚¯ã‚¹ã‚’äº‹å‰ã«é™¤å¤–ã—ã€NMSå‡¦ç†ã‚’é«˜é€ŸåŒ–
     */
    private fun nmsPoseDetections(
        detections: List<PoseDetection>,
        iouThreshold: Float
    ): List<PoseDetection> {
        // ååˆ†ã«é«˜ã„ä¿¡é ¼åº¦ã®ãƒœãƒƒã‚¯ã‚¹ã®ã¿ã‚’é¸æŠï¼ˆæ—©æœŸæåˆˆã‚Šï¼‰
        val confidenceThreshold = 0.25f  // è¨­å®šå¯èƒ½ãªé–¾å€¤
        val filteredDetections = detections.filter { it.box.conf >= confidenceThreshold }
        
        // æ®‹ã‚Šã®ãƒœãƒƒã‚¯ã‚¹ãŒå°‘ãªã„å ´åˆã€æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³
        if (filteredDetections.size <= 1) {
            return filteredDetections
        }
        
        // ä¿¡é ¼åº¦ã§é™é †ã‚½ãƒ¼ãƒˆ
        val sorted = filteredDetections.sortedByDescending { it.box.conf }
        val picked = mutableListOf<PoseDetection>()
        val used = BooleanArray(sorted.size)

        for (i in sorted.indices) {
            if (used[i]) continue

            val d1 = sorted[i]
            picked.add(d1)

            // å†…å´ã®ãƒ«ãƒ¼ãƒ—ã§ã®æ¯”è¼ƒå›æ•°ã‚’æ¸›ã‚‰ã™ãŸã‚ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ç”¨
            for (j in i + 1 until sorted.size) {
                if (used[j]) continue
                val d2 = sorted[j]
                if (iou(d1.box.xywh, d2.box.xywh) > iouThreshold) {
                    used[j] = true
                }
            }
        }
        
        // Debug log for final results
        Log.d(TAG, "ğŸ¯ NMS complete - returning ${picked.size} detections from ${detections.size} input")
        picked.forEachIndexed { idx, detection ->
            Log.d(TAG, "ğŸ“Š Final detection $idx - keypoints count: ${detection.keypoints.xy.size}")
            val highConfKps = detection.keypoints.conf.count { it > 0.25f }
            val avgConf = if (detection.keypoints.conf.isNotEmpty()) detection.keypoints.conf.average() else 0.0
            Log.d(TAG, "ğŸ’¯ Final detection $idx - high conf keypoints (>0.25): $highConfKps, avg conf: $avgConf")
        }
        
        return picked
    }

    /**
     * IoUè¨ˆç®—
     */
    private fun iou(a: RectF, b: RectF): Float {
        val interLeft = max(a.left, b.left)
        val interTop = max(a.top, b.top)
        val interRight = min(a.right, b.right)
        val interBottom = min(a.bottom, b.bottom)
        val interW = max(0f, interRight - interLeft)
        val interH = max(0f, interBottom - interTop)
        val interArea = interW * interH
        val unionArea = a.width() * a.height() + b.width() * b.height() - interArea
        return if (unionArea <= 0f) 0f else (interArea / unionArea)
    }

    /**
     * ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æç”»ã—ãŸãƒ“ãƒƒãƒˆãƒãƒƒãƒ—ã‚’è¿”ã™
     */
    private fun drawPoseOnBitmap(
        bitmap: Bitmap,
        keypointsList: List<Keypoints>,
        boxes: List<Box>
    ): Bitmap {
        val output = bitmap.copy(Bitmap.Config.ARGB_8888, true)
        val canvas = Canvas(output)
        val paint = Paint().apply {
            style = Paint.Style.FILL
            color = Color.GREEN
            strokeWidth = 5f
        }
        // ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»ç”¨
        val boxPaint = Paint().apply {
            style = Paint.Style.STROKE
            color = Color.RED
            strokeWidth = 3f
        }

        // å„Personã«ã¤ã„ã¦æç”»
        for ((index, person) in keypointsList.withIndex()) {
            // ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æç”»
            val boxRect = boxes[index].xywh
            canvas.drawRect(boxRect, boxPaint)

            // ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æç”»
            for ((i, kp) in person.xy.withIndex()) {
                // confãŒä¸€å®šä»¥ä¸Šã®ã¿å¯è¦–åŒ–ã—ãŸã‘ã‚Œã°é©å®œåˆ¤å®š
                if (person.conf[i] > 0.25f) {
                    canvas.drawCircle(kp.first, kp.second, 8f, paint)
                }
            }
            // å¿…è¦ã«å¿œã˜ã¦ã‚¹ã‚±ãƒ«ãƒˆãƒ³(éª¨æ ¼ç·š)æç”»ã‚’è¿½åŠ 
        }
        return output
    }

    /**
     * PoseDetection ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
     */
    private data class PoseDetection(
        val box: Box,
        val keypoints: Keypoints
    )
}
